import os, glob
import winsound
import operator
import threading
import tkinter.messagebox
from tkinter.filedialog import askopenfilename, askopenfilenames
from tkinter import *
from tkinter.ttk import *
import subprocess

import PIL.Image
import PIL.ImageTk
import cv2
from utils import *
import tiff_scenario, png_scenario, bmp_scenario


def isHangul(text):
    encText = text
    hanCount = len(re.findall(u'[\u3130-\u318F\uAC00-\uD7A3]+', encText))
    return hanCount > 0

class VideoCaptureYUV:
    def __init__(self, filename, size):
        self.height, self.width = size
        self.frame_len = self.width * self.height * 3 / 2
        self.f = open(filename, 'rb')
        self.shape = (int(self.height * 1.5), self.width)

    def isOpened(self):
        return 0

    def read_raw(self):
        try:
            raw = self.f.read(int(self.frame_len))
            yuv = np.frombuffer(raw, dtype=np.uint8)
            yuv = yuv.reshape(self.shape)
        except Exception as e:
            print(str(e))
            return False, None
        return True, yuv

    def read(self):
        ret, yuv = self.read_raw()
        if not ret:
            return ret, yuv
        bgr = cv2.cvtColor(yuv, cv2.COLOR_YUV420p2BGR)
        return ret, bgr


class LoadDisplay(object):  # ui ì˜ìƒì°½ í´ë˜ìŠ¤
    # ì¶”ê°€í•´ì•¼í•  ë””ìŠ¤í”Œë ˆì´ í´ë˜ìŠ¤ ê¸°ëŠ¥: í”„ë¡œê·¸ë˜ìŠ¤ë°”, ëª¨ë“ ë¹„ë””ì˜¤ì‹œí€€ìŠ¤ê°€ 33msì˜ í”„ë ˆì„ë ˆì´íŠ¸ë¥¼ ê°€ì§€ëŠ”ë¬¸ì œ, ë“œë˜ê·¸ì‹œ í´ë¦­ë˜ëŠ” ë¬¸ì œ
    pausedisplay = 1  # í´ë˜ìŠ¤ê°„ ê³µí†µë³€ìˆ˜
    progressbar = 0

    def __init__(self, win, x, y):
        self.win = win
        self.frame = None
        self.frame_count = 0.99
        self.x = x
        self.y = y
        self.f_width = 352
        self.f_height = 288
        self.video_source = ''
        self.move_x = 0
        self.move_y = 0
        self.zoom_x = 1
        self.zoom_y = 1
        self.vid = cv2.VideoCapture(self.video_source)
        self.i_width = 55555
        self.i_height = 55555
        self.name = ""

        if not self.vid.isOpened():
            pass  # raise ValueError("Unable", self.video_source)
        else:
            pass  # self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)
        self.canvas = tkinter.Canvas(self.win, width=self.f_width, height=self.f_height, bg="white", bd=0, highlightthickness=0, relief='ridge')
        self.canvas.pack(pady=(3, 1), padx=(1, 2))

        self.canvas.bind("<Button-1>", self.l_click)
        self.canvas.bind("<Button-3>", self.r_click)
        self.canvas.bind("<B1-Motion>", self.drag)
        self.canvas.bind("<space>", self.keypress)
        self.canvas.bind("<ButtonRelease-1>", self.l_click_off)
        self.canvas.bind("<MouseWheel>", self.mousewheel)

        self.delay = 33
        self.update()

        self.r_popup = Menu(window, tearoff=0)
        self.r_popup.add_command(label="x0.5", command=lambda: self.zoom_change(0.5))
        self.r_popup.add_command(label="x1.0", command=lambda: self.zoom_change(1.0))
        self.r_popup.add_command(label="x1.5", command=lambda: self.zoom_change(1.5))
        self.r_popup.add_command(label="x2.0", command=lambda: self.zoom_change(2.0))

    def __del__(self):
        if self.vid.isOpened():
            self.vid.release()

    def zoom_change(self, zoom):
        if zoom == 1.0:
            self.move_x = 0
            self.move_y = 0
        self.zoom_x = zoom
        self.zoom_y = zoom
        frame = cv2.resize(self.frame, None, fx=self.zoom_x, fy=self.zoom_y, interpolation=cv2.INTER_LINEAR)

    def changevideo(self, src=''):

        def set_srctext_and_return(s):
            srctext = os.path.basename(s)               # íŒŒì¼ì´ë¦„ ì¶œë ¥ìš©
            text = self.win.children['!text']
            text.configure(state='normal')
            text.delete(1.0, END)
            text.insert(END, srctext)
            text.tag_add('cen', 1.0, END)               # ê°€ìš´ë°ì •ë ¬
            text.tag_config('cen', justify='center')    # ê°€ìš´ë°ì •ë ¬
            text.configure(state='disabled')
            canvas_loading.forget()
            return s

        LoadDisplay.pausedisplay = 1
        if src == '':
            tem = askopenfilename(initialdir="", filetypes=(("All", "*.*"), ("All Files", "*.*")), title="Choose a file.")
            if tem == '':
                return ''  # ask ì°½ cancel í•œ ê²½ìš°
            self.video_source = tem
        elif src == 'close':
            self.vid = cv2.VideoCapture('clod.png')
            print('ë””ìŠ¤í”Œë ˆì´ ë‹«ê¸°')
            ret, self.frame = self.get_frame()
            self.vid.release()
            return set_srctext_and_return('')
        else:
            self.video_source = src

        canvas_loading.show()
        if self.vid.isOpened():
            self.vid.release()  # ë§Œì•½ í´ë˜ìŠ¤ì— ì´ì „ ì˜ìƒì´ ì—´ë ¤ìˆë‹¤ë©´, ì†Œë©¸ì²˜ë¦¬
        self.vid = cv2.VideoCapture(self.video_source)
        self.name = os.path.splitext(self.video_source)[1]

        if not self.vid.isOpened():  # ì—´ë¦¬ì§€ ì•Šì•˜ë‹¤ë©´
            if os.path.isfile(self.video_source):  ## ì˜ìƒ ì¡´ì¬   png,  YUV ì¼€ì´ìŠ¤?
                print('(debug) imreadë¡œ ì‹œë„')
                if isHangul(self.video_source): print_dual(self.canvas.master.master.children['!labelframe3'].children['!text'], "(debug) cv2.imread png: ê²½ë¡œì— í•œê¸€ ì£¼ì†Œê°€ í¬í•¨ë˜ì–´ ìˆì–´ ë””ì½”ë”© ë¶ˆê°€"); return
                self.frame = cv2.imread(self.video_source)
                if self.frame is not None:  # imreadë¡œ ì—´ê¸° ì„±ê³µ
                    b, g, r = cv2.split(self.frame)
                    self.frame = cv2.merge([r, g, b])
                    self.i_width = self.frame.shape[1]
                    self.i_height = self.frame.shape[0]
                    ratio = 352 / self.i_width
                    self.zoom_x = ratio
                    self.zoom_y = ratio
                    self.move_x = 0
                    self.move_y = 0
                    self.frame = cv2.resize(self.frame, None, fx=1, fy=1, interpolation=cv2.INTER_LINEAR)
                    self.frame_num_p = 0
                    window.update()
                    time.sleep(0.01)
                    sli1.set(0)
                    sli2.set(0)
                    canvas_loading.forget()
                    return set_srctext_and_return(self.video_source)
                else:  # imreadë¡œ ì—´ê¸° ì‹¤íŒ¨
                    if '.yuv' in self.video_source:
                        self.vid = VideoCaptureYUV(self.video_source, (288, 352))
                        ret, self.frame = self.vid.read()
                        print_dual(self.canvas.master.master.children['!labelframe3'].children['!text'], "(debug) YUV ì—´ê¸° ì™„ë£Œ, ì´ë¯¸ì§€ëŠ” ë³´ì´ë‚˜ ì¸ì½”ë”©ëœ ìƒíƒœê°€ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì‹œë‚˜ë¦¬ì˜¤ ì ìš© ë¶ˆê°€")
                        return set_srctext_and_return(self.video_source)
                    else:
                        # print_dual(self.canvas.master.master.children['!labelframe3'].children['!text'], "(debug) ë¬´ì—‡ì„ ì—°ê²ƒ?")
                        self.vid = cv2.VideoCapture('errd2.png')
                        print('ì˜¤ë¥˜ë””ìŠ¤í”Œë ˆì´ ì¶œë ¥')
                        ret, self.frame = self.get_frame()
            else:
                print("@@@@@@@@@@@@@@@@@@@@@@@@@@@")  ## ì˜ìƒ ë…¸ì¡´ì¬
                print("error, file not exist in %s" % self.video_source)
                ## ì—ëŸ¬ì˜ìƒ ë©”ì„¸ì§€ ë””ìŠ¤í”Œë ˆì´ê¸°ëŠ¥ ë„£ê¸°
                self.video_source = ""
                return set_srctext_and_return('')

        else:  # vid.isOpened True ì¼ë•Œ:  ì˜ìƒ ì •ë³´ë¥¼ ì–»ì
            ret, self.frame = self.get_frame()  # ë™ì˜ìƒì˜ ì´ˆê¸° 1í”„ë ˆì„ ì–»ì–´ ë„ìš°ê¸°
            if self.frame is None:  ## íŒŒì¼ì€ ì¡´ì¬í•˜ì§€ë§Œ ë””ì½”ë”©ì´ ì•ˆëë‹¨ëœ»    ## IVC ë””ì½”ë”ë¡œ ì‹œë„
                self.vid.release()
                print("IVC ë””ì½”ë”ë¡œ ì‹œë„")
                subprocess.run("ldecod_ivc.exe %s 1t_youcandelete_%s" % (self.video_source, os.path.basename(self.video_source)), stdout=subprocess.DEVNULL)  # í˜„ì¬í´ë”ì— ì¬ì¸ì½”ë”©ëœ ì„ì‹œíŒŒì¼ ìƒì„±
                yuv_src = '1t_youcandelete_' + os.path.basename(self.video_source)
                subprocess.run("ffmpeg.exe -f rawvideo -s 352x288 -pix_fmt yuv420p -i %s -c:v hevc -y %s.hevc" % (yuv_src, os.path.splitext(yuv_src)[0]), stdout=subprocess.DEVNULL)
                # if os.path.isfile(os.path.splitext(yuv_src)[0] + '.hevc'): íŒŒì¼ì´ì¡´ì¬í•˜ì§€ì•Šì„ì´ìœ ëŠ”ì—†ì„ê±¸
                if os.path.getsize(os.path.splitext(yuv_src)[0] + '.hevc') > 1:
                    self.vid = cv2.VideoCapture(os.path.splitext(yuv_src)[0] + '.hevc')
                else:
                    self.vid = cv2.VideoCapture('errd1.png')
                    print('ì˜¤ë¥˜ë””ìŠ¤í”Œë ˆì´ ì¶œë ¥')  ## ivcë””ì½”ë”ë¡œë„ ì•ˆëœ¬ë‹¤ë©´ ì‹œí€€ìŠ¤ëŠ” ì—ëŸ¬ì˜ìƒ ì¼ê²ƒì„     í™”ë©´ìƒì— ì—ëŸ¬ ë©”ì„¸ì§€ë¡œ ë””ìŠ¤í”Œë ˆì´ê¸°ëŠ¥ ë„£ê¸°
                ret, self.frame = self.get_frame()
            self.frame_count = self.vid.get(cv2.CAP_PROP_FRAME_COUNT)  ##### ì •ë¦¬ì¢€ í• ê²ƒ
            if self.frame_count < 1 or self.frame_count > 30000:  # ìŒìˆ˜ê±°ë‚˜ ë„ˆë¬´í¬ë©´
                self.frame_count = 300
                self.vid.set(7, 300)
                print('í”„ë ˆì„ì¹´ìš´íŠ¸ í—¤ë”ì— ì˜¤ë¥˜ê°€ ìˆìŒ', self.frame_count, 'ìœ¼ë¡œ ë³€ê²½')
        self.i_width = self.vid.get(3)
        self.i_height = self.vid.get(4)
        ratio = 352 / self.i_width
        self.zoom_x = ratio
        self.zoom_y = ratio
        self.move_x = 0
        self.move_y = 0
        self.frame = cv2.resize(self.frame, None, fx=1, fy=1, interpolation=cv2.INTER_LINEAR)
        self.frame_num_p = 0
        window.update()
        time.sleep(0.01)
        sli1.set(0)
        sli2.set(0)
        return set_srctext_and_return(self.video_source)

    def get_frame(self):
        if self.vid.isOpened():  # self.vid.set(cv2.CV_CAP_PROP_POS_FRAMES, frame_number - 1)
            try:
                ret, frame = self.vid.read()  # cvê°€ ì½”ë±ëª¨ë¥¼ê²½ìš° ì—ëŸ¬ë¿œìŒ
            except:
                None
            LoadDisplay.progressbar = self.vid.get(cv2.CAP_PROP_POS_FRAMES)
            if ret:
                return 2, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # success
            else:
                self.vid = cv2.VideoCapture(self.video_source)  # opencv ì´ìƒí•œê²Œ í”„ë ˆì„ ì¬ìƒ í• ë‹¹ëŸ‰ë§Œ ì±„ìš°ë©´ ì¢…ë£Œë˜ë²„ë¦¬ë„¤ ã„·  bitì€ ì˜¤ë¥˜ë‚ ë“¯
                LoadDisplay.pausedisplay = 1
                return 3, None  # ì‹œí€€ìŠ¤ ë ë¹ˆ í”„ë ˆì„
        else:
            return 0, 0  # ì´ˆê¸° init ìƒíƒœ

    def update(self):
        if LoadDisplay.pausedisplay == 1:
            ret = 3  # pause ê¸°ëŠ¥
        else:
            ret, temframe = self.get_frame()  # Get a frame from the video source
            cur = self.vid.get(1)
            if self.frame_count < cur: self.frame_count = cur
            if self.canvas.master.winfo_name() == '!labelframe':  # labelframe2ëŠ” ìš°ì¸¡ ë””ìŠ¤í”Œë ˆì´ì„, ì¦‰ ì¢Œì¸¡ë””ìŠ¤í”Œë ˆì´ ê¸°ì¤€ìœ¼ë¡œ ìŠ¬ë¼ì´ë“œê°€ ì›€ì§ì¸ë‹¤
                self.canvas.master.master.children['!scale'].set((cur / self.frame_count) * 100)

        if ret == 2:  # ì¼ë°˜ ì¬ìƒ ì‹œ
            self.frame = temframe
            temframe = cv2.resize(temframe, None, fx=self.zoom_x, fy=self.zoom_y, interpolation=cv2.INTER_LINEAR)
            self.photo = PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(temframe))
            self.canvas.create_image(self.move_x, self.move_y, image=self.photo, anchor=tkinter.NW)
        if ret == 3:  # ì˜ìƒì˜ ëì¼ë•Œ ë§ˆì§€ë§‰ í”„ë ˆì„ì„ ì¬ìƒí•˜ë„ë¡
            if self.frame is None:
                pass
            else:
                temframe = cv2.resize(self.frame, None, fx=self.zoom_x, fy=self.zoom_y, interpolation=cv2.INTER_LINEAR)
                self.photo = PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(temframe))
                self.canvas.create_image(self.move_x, self.move_y, image=self.photo, anchor=tkinter.NW)
        window.after(self.delay, self.update)  # ë°˜ë³µ í˜¸ì¶œ

    def l_click(self, event):
        self.lock_x = -self.move_x + event.x
        self.lock_y = -self.move_y + event.y

    def r_click(self, event):
        try:
            self.r_popup.tk_popup(event.x_root + 30, event.y_root + 10, 0)
        finally:
            self.r_popup.grab_release()
        pass

    def drag(self, event):
        self.move_x = - (self.lock_x - event.x)
        self.move_y = - (self.lock_y - event.y)

    def keypress(self, event):  # canvas ì—ì„  ì‘ë™ì•ˆí•˜ë‚˜ë´„
        kp = repr(event.char)
        print("pressed", kp)  # repr(event.char))
        if (kp == 'x'):
            print("pressed x", repr(event.char))

    def l_click_off(self, event):
        if self.lock_x == -self.move_x + event.x and self.lock_y == -self.move_y + event.y:
            if LoadDisplay.pausedisplay == 1:
                LoadDisplay.pausedisplay = 0
            else:
                LoadDisplay.pausedisplay = 1

    def mousewheel(self, event):
        if event.delta > 0:
            self.move_x = self.move_x - (self.i_width * self.zoom_x) * 0.125 + 2.5
            self.move_y = self.move_y - (self.i_height * self.zoom_y) * 0.125 + 2.5
            self.zoom_x = self.zoom_x * 1.333333
            self.zoom_y = self.zoom_y * 1.333333
        else:
            self.move_x = self.move_x + (self.i_width * self.zoom_x) * 0.125 - 2.5
            self.move_y = self.move_y + (self.i_height * self.zoom_y) * 0.125 - 2.5
            self.zoom_x = self.zoom_x * 0.750000
            self.zoom_y = self.zoom_y * 0.750000

    def touch_slide(self, event):
        if self.vid.isOpened():
            self.vid.set(cv2.CAP_PROP_POS_FRAMES, LoadDisplay.progressbar)


def set_slider(slidername, *args):
    t = 0
    for i in args:
        if t < i.frame_count:
            t = i.frame_count


def print_dual(text, aa):
    if aa == '': return;
    now = datetime.now(); strt = '[%d.%02d.%02d %d:%02d:%02d] ' % (now.year, now.month, now.day, now.hour, now.minute, now.second)
    print(strt, end='')
    text.insert(END, strt)
    print(aa)
    if type(aa) == str:
        text.insert(END, aa + '\n')
    if type(aa) == list:
        print_dual_nocl(text, '   frequency is [')
        for a in aa:
            print_dual_nocl(text, '%d, ' % (a))
        print_dual_nocl(text, ']\n')
    text.see(END)
    text.update()


def print_dual_nocl(text, aa):
    print(aa, end='')
    if type(aa) == str: text.insert(END, aa)
    if type(aa) == list:
        print_dual_nocl(text, '   frequency is [')
        for a in aa:
            print_dual_nocl(text, '%d, ' % (a))
        print_dual_nocl(text, ']\n')
    text.update()

def do_inv(text, seq):
    src_plus_name = os.path.splitext(seq)[0]   # íŒŒì¼ê²½ë¡œ+íŒŒì¼ì´ë¦„
    ext = os.path.splitext(seq)[1]             # í™•ì¥ì
    print_dual(text, 'inverse ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..')
    bits_inv = bitstring.BitStream(~bitstring.Bits(filename=seq))
    bits_inv.tofile(open(src_plus_name + '_restored' + ext, 'wb'))
    vid4.changevideo(src_plus_name + '_restored' + ext)
    print_dual(text, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')

def do_dxor(text, seq):
    src_plus_name = os.path.splitext(seq)[0]   # íŒŒì¼ê²½ë¡œ+íŒŒì¼ì´ë¦„
    ext = os.path.splitext(seq)[1]             # í™•ì¥ì
    print_dual(text, 'xor ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..')
    bitstream = bitstring.ConstBitStream(filename=seq)
    bitstream = dxor_fast_bitstream(bitstream)
    (open(src_plus_name + '_restored' + ext, 'wb')).write(bitstream)
    vid4.changevideo(src_plus_name + '_restored' + ext)
    print_dual(text, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')


def non_block_threding_popen(text, src, encoding='utf-8'):  # stdoutë¥¼ readë¡œ ì½ìœ¼ë©´ ë¨¹í†µë˜ëŠ” í˜„ìƒ ê³ ì¹˜ëŠ” í•¨ìˆ˜
    from queue import Queue
    def enqueue_output(out, queue):
        try:
            for line in iter(out.readline, b''):
                queue.put(line)
        except:
            return  # print("íƒˆì¶œ");

    def time_write():
        for n in range(2, 8):
            tem = text.get('end-%dlines' % n, 'end-%dlines' % (n - 1))
            if tem == '': break
            if tem[0] != '[':
                now = datetime.now()
                text.insert('end-%dlines' % n, '[%d.%02d.%02d %d:%02d:%02d] ' % (now.year, now.month, now.day, now.hour, now.minute, now.second))

    LoadDisplay.pausedisplay = 1
    canvas_loading.show()
    p = subprocess.Popen(src, encoding=encoding, stdout=subprocess.PIPE)
    q = Queue()
    t = threading.Thread(target=enqueue_output, args=(p.stdout, q))
    t.daemon = True
    t.start()

    while p.poll() is None:  # read line without blocking
        try:
            line = q.get(timeout=.1)  # or q.get(timeout=.1)
        except:
            time_write()
            text.see(END)
            window.update()  # print('no output yet')
        else:  # got line
            text.insert(END, line)
            continue
    time.sleep(0.01)
    p.stdout.close()  # íŒŒì´ì¬..
    time_write()
    text.see(END)
    canvas_loading.forget()
    text_ = text.get('end-2lines', END)
    if text_[-5:-4] is '':
        text.delete('end-5c', 'end-1c')
    after_text = text.get('end-2lines', END)


#########################################################################################################
#########################################################################################################
#########################################################################################################
#########################################################################################################
def srcs_g(a):
    srcs_g.count = a



#                           ê°€ëŠ¥ ì½”ë±
# "Scenario-1 inverse"          ëª¨ë‘
# "Scenario-2 xor"              ëª¨ë‘
# "Scenario-3 ë”ë¯¸-íˆë“ "         mpeg2 263 264 hevc ivc        (vp8 ì œì™¸)
# "Scenario-4 start code"      mpeg2 264 hevc ivc            (vp8 263 ì œì™¸)
# "Scenario-5 jpg, j2k"        jpg j2k
# "Scenario-6 bmp"             bmp
# "Scenario-7 png"             png
# "Scenario-8 tiff"            tiff
# * vp8 = webm , ivc = bit

def scenario_act(event):  ### ë³€ì¡°ê³¼ì • ###                  # ì´ í•¨ìˆ˜ëŠ” input stream ë²„íŠ¼ì„ ëˆŒëŸ¬ë„ í˜¸ì¶œë˜ê³  comboboxë¥¼ ì„ íƒí•´ë„ í˜¸ì¶œë¨ event ì¸ìì˜ ì°¨ì´
    if event == 'askmode':          # input stream ë²„íŠ¼ì„ í†µí•œ ì ‘ê·¼ì‹œ
        srcs_g.count = askopenfilenames(initialdir="", filetypes=(("All", "*.*"), ("All Files", "*.*")), title="Choose a file.")
        srcs = srcs_g.count
        if len(srcs) == 0:      # ì‚¬ìš©ìê°€ ask ì°½ì„ ìº”ìŠ¬ ëˆ„ë¥¸ ê²½ìš° ì•„ì›ƒ
            frame1.children['!combobox']['values'] = ("Scenario-1 inverse", "Scenario-2 xor", "Scenario-3 ë”ë¯¸-íˆë“ ", "Scenario-4 start code", "Scenario-5 jpg, j2k", "Scenario-6 bmp", "Scenario-7 png", "Scenario-8 tiff")
            return
        if len(srcs) >= 1:      # í•˜ë‚˜ ì„ íƒí•œê²½ìš° ë³´ì—¬ì£¼ê¸°ë§Œ í•˜ê³  ì•„ì›ƒ  ë‘ê°œì´ìƒ ì„ íƒí•œ ê²½ìš° ì²«ë²ˆì§¸ íŒŒì¼ì˜ í™”ë©´ë§Œ ë³´ì—¬ì£¼ê³  ì•„ì›ƒ
            c_i = ["Scenario-1 inverse" , "Scenario-2 xor", ' ', ' ', ' ', ' ', ' ', ' ']
            for s in srcs:
                ext = os.path.splitext(s)[1]
                if ext in ['.jpg','.j2k']: c_i[4] = "Scenario-5 jpg, j2k"
                if ext in '.bmp' : c_i[5] = "Scenario-6 bmp"
                if ext in '.png' : c_i[6] = "Scenario-7 png"
                if ext in '.tiff': c_i[7] = "Scenario-8 tiff"
                if ext in '.m2v' : c_i[2] = "Scenario-3 ë”ë¯¸-íˆë“ "; c_i[3] = "Scenario-4 start code";
                if '263' in ext  : c_i[2] = "Scenario-3 ë”ë¯¸-íˆë“ "
                if '264' in ext  : c_i[2] = "Scenario-3 ë”ë¯¸-íˆë“ "; c_i[3] = "Scenario-4 start code";
                if ext in '.hevc': c_i[2] = "Scenario-3 ë”ë¯¸-íˆë“ "; c_i[3] = "Scenario-4 start code";
                if ext in '.bit' : c_i[2] = "Scenario-3 ë”ë¯¸-íˆë“ "; c_i[3] = "Scenario-4 start code";
            while ' '  in c_i: c_i.remove(' ')           # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì œê±°
            frame1.children['!combobox']['values'] = c_i
            print_dual(text_1_3, f' {len(srcs)}ê°œì˜ ì…ë ¥ ì˜ìƒì„ ì„ íƒí•˜ì˜€ìŠµë‹ˆë‹¤.  ')
            vid1.changevideo(srcs[0])
            return


    # combobox ë¦¬ìŠ¤íŠ¸ë¥¼ í†µí•œ ì ‘ê·¼ì‹œ
    srcs = srcs_g.count
    if len(srcs) == 0:  return     # ì…ë ¥ì˜ìƒì„ ì•„ì§ ì„ íƒí•˜ì§€ ì•Šì•˜ì„ ê²½ìš° ê·¸ëƒ¥ ì•„ì›ƒ

    for iii, seq1 in enumerate(srcs):
        if seq1 == '' and event.widget.current() != 9:
            print_dual(text_1_3, 'input streamì„ ì§€ì •í•´ ì£¼ì„¸ìš”')
            return
        src_plus_name = os.path.splitext(seq1)[0]   # íŒŒì¼ê²½ë¡œ+íŒŒì¼ì´ë¦„
        ext = os.path.splitext(seq1)[1]             # í™•ì¥ì
        name = os.path.basename(src_plus_name)      # íŒŒì¼ì´ë¦„

        print_dual(text_1_3, f'({iii + 1}/{len(srcs)}) {name}{ext}')
        vid1.changevideo(seq1)                      # ì…ë ¥ì˜ìƒ ë„ìš°ê¸°

        if 'Scenario-1' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤1 inverse ë³€ì¡°
            print_dual(text_1_3, 'inverse ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤..')
            bits_inv = bitstring.BitStream(~bitstring.Bits(filename=seq1))
            bits_inv.tofile(open(src_plus_name + '_inv' + ext, 'wb'))  # ê²½ë¡œ/seq.í™•ì¥ì -> ê²½ë¡œ/seq_inv.í™•ì¥ì
            vid2.changevideo(src_plus_name + '_inv' + ext)
            print_dual(text_1_3, 'ë³€ì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')

        elif 'Scenario-2' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤2 xor ë³€ì¡°
            print_dual(text_1_3, 'xor ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤..')
            bitstream = bitstring.ConstBitStream(filename=seq1)
            bitstream = xor_fast_bitstream(bitstream)
            (open(src_plus_name + '_xor' + ext, 'wb')).write(bitstream)  # ê²½ë¡œ/seq.í™•ì¥ì -> ê²½ë¡œ/seq_xor.í™•ì¥ì
            vid2.changevideo(src_plus_name + '_xor' + ext)
            print_dual(text_1_3, 'ë³€ì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')

        elif 'Scenario-3' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤3 ë”ë¯¸-íˆë“  ë³€ì¡°               í˜„ì¬ mpeg2,263,264,265,IVC ë§Œ ì§€ì› ë¨
            if ext in 'webm': print_dual(text_1_3, 'vp8 ì€ ë”ë¯¸-íˆë“  ë³€ì¡°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'); continue
            if ext in ['jpg', 'j2k', 'bmp', 'tiff', 'png']: print_dual(text_1_3, 'ì´ë¯¸ì§€ í¬ë©§ì€ ë”ë¯¸-íˆë“  ë³€ì¡°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'); continue
            print_dual(text_1_3, 'ìˆ¨ê¸¸ ì˜ìƒì„ ì¶”ê°€ë¡œ ì„ íƒ í•´ ì£¼ì„¸ìš”')
            seq2 = askopenfilename(initialdir="", filetypes=(("All", "*.*"), ("All Files", "*.*")), title="Choose a file.")  # ë”ë¯¸-íˆë“  ë³€ì¡°ê³¼ì •ì— í•„ìš”í•œ ì¶”ê°€ì‹œí€€ìŠ¤(íˆë“ ) ì—´ê¸°
            if seq2 == '': print_dual(text_1_3, 'ì¶”ê°€ ì˜ìƒì„ ì„ íƒí•˜ì§€ ì•Šì•„ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤'); continue
            print_dual(text_1_3, 'ë”ë¯¸-íˆë“  ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤..')
            non_block_threding_popen(text_1_3, "python.exe dummy_hidden.py %s %s" % (seq1, seq2))  # ë”ë¯¸-íˆë“  ì‹œë‚˜ë¦¬ì˜¤ ë³€ì¡° ì‹¤í–‰
            seq3 = os.path.splitext(seq1)[0] + '_' + os.path.basename(seq2)
            vid2.changevideo(seq3) if os.path.isfile(seq3) else print_dual(text_1_3, '%s ì¡´ì¬í•˜ì§€ ì•ŠìŒ' % seq3)  # ë”ë¯¸-íˆë“  ì‹¤í–‰ í›„ ì™„ë£Œëœ íŒŒì¼ vid2ì— ë„ìš°ê¸°
            print_dual(text_1_3, 'ë³€ì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')

        elif 'Scenario-4' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤4 header ë³€ì¡°
            if ext in ['webm', 'bit']: print_dual(text_1_3, 'vp8 ì€ headerë³€ì¡°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'); continue
            if ext in ['jpg', 'j2k', 'bmp', 'tiff', 'png']: print_dual(text_1_3, 'ì´ë¯¸ì§€ í¬ë©§ì€ headerë³€ì¡°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'); continue
            print_dual(text_1_3, 'header ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤..')
            if subprocess.call("start_code_encryptor.exe %s" % seq1) == 0: vid2.changevideo(seq1 + '.st'); print_dual(text_1_3, 'ë³€ì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
            else: print_dual(text_1_3, 'header ë³€ì¡° ë¶ˆê°€í•œ ë¹„íŠ¸ìŠ¤íŠ¸ë¦¼ì…ë‹ˆë‹¤.')

        elif 'Scenario-5' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤5 JPEG ì–‘ìí™” í…Œì´ë¸” ë³€ì¡°
            print_dual(text_1_3, 'JPEG ì–‘ìí™” í…Œì´ë¸” ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤.')
            if ext in ['.jpg', '.j2k']:
                try:
                    non_block_threding_popen(text_1_3, "python.exe JPEG.py %s %d" % (seq1, 0))
                    seq2 = src_plus_name + '_Distorted' + ext
                    vid2.changevideo(seq2) if os.path.isfile(seq2) else print_dual(text_1_3, '%s ì¡´ì¬í•˜ì§€ ì•ŠìŒ' % seq2)
                except:
                    print_dual(text_1_3, 'JPEG ì–‘ìí™” í…Œì´ë¸” ë³€ì¡°ê°€ ë¶ˆê°€í•©ë‹ˆë‹¤.')
            else:
                print_dual(text_1_3, 'ì…ë ¥ ì˜ìƒì´ \'JPEG\' ì˜ìƒì´ ì•„ë‹™ë‹ˆë‹¤.')

        elif 'Scenario-6' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤6 BMP ë³€ì¡°
            print_dual(text_1_3, 'BMP ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤..')
            if ext in ['.bmp']:
                try:
                    non_block_threding_popen(text_1_3, "python.exe bmp_scenario.py %s %d" % (seq1, 0))
                    seq2 = src_plus_name + '_Distorted' + ext
                    vid2.changevideo(seq2) if os.path.isfile(seq2) else print_dual(text_1_3, '%s ì¡´ì¬í•˜ì§€ ì•ŠìŒ' % seq2)
                except:
                    print_dual(text_1_3, 'BMP ë³€ì¡°ê°€ ë¶ˆê°€í•©ë‹ˆë‹¤.')
            else:
                print_dual(text_1_3, 'ì…ë ¥ ì˜ìƒì´ \'BMP\' ì˜ìƒì´ ì•„ë‹™ë‹ˆë‹¤.')

        elif 'Scenario-7' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤7 PNG ë³€ì¡°
            print_dual(text_1_3, 'PNG ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤..')
            if ext in ['.png']:
                try:
                    non_block_threding_popen(text_1_3, "python.exe png_scenario.py %s %d" % (seq1, 0))
                    seq2 = src_plus_name + '_Distorted' + ext
                    vid2.changevideo(seq2) if os.path.isfile(seq2) else print_dual(text_1_3, '%s ì¡´ì¬í•˜ì§€ ì•ŠìŒ' % seq2)
                except:
                    print_dual(text_1_3, 'PNG ë³€ì¡°ê°€ ë¶ˆê°€í•©ë‹ˆë‹¤.')
            else:
                print_dual(text_1_3, 'ì…ë ¥ ì˜ìƒì´ \'PNG\' ì˜ìƒì´ ì•„ë‹™ë‹ˆë‹¤.')

        elif 'Scenario-8' in event.widget.get():  ## ì‹œë‚˜ë¦¬ì˜¤8 TIFF ë³€ì¡°
            print_dual(text_1_3, 'TIFF ë³€ì¡° ì¤‘ì…ë‹ˆë‹¤..')
            if ext in ['.tiff']:
                try:
                    non_block_threding_popen(text_1_3, "python.exe tiff_scenario.py %s %d" % (seq1, 0))
                    seq2 = src_plus_name + '_Distorted' + ext
                    vid2.changevideo(seq2) if os.path.isfile(seq2) else print_dual(text_1_3, '%s ì¡´ì¬í•˜ì§€ ì•ŠìŒ' % seq2)
                except:
                    print_dual(text_1_3, 'TIFF ë³€ì¡°ê°€ ë¶ˆê°€í•©ë‹ˆë‹¤.')
            else:
                print_dual(text_1_3, 'ì…ë ¥ ì˜ìƒì´ \'TIFF\' ì˜ìƒì´ ì•„ë‹™ë‹ˆë‹¤.')

        print_dual(text_1_3, "ã€€")
        window.focus_force()
        # winsound.PlaySound('SystemQuestion', winsound.SND_ALIAS)  # ì‚¬ìš´ë“œì— ë”œë ˆì´ê°€ í•¨ê»˜ ìˆë‹¤.. ã„·ã„·
        # time.sleep(0.5)


#########################################################################################################
#########################################################################################################
#########################################################################################################
# 1. ì–´ë–¤ ì‹œë‚˜ë¦¬ì˜¤ê°€ ì ìš©ë˜ì–´ìˆëŠ”ì§€ íŒë‹¨
# 2. íŒë‹¨ëœ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ê° ì—°êµ¬ì‹¤ì˜ ë³µì¡°ê³¼ì • ì‹¤í–‰
def scenario_inv_act():  ### ë³µì¡°ê³¼ì •   ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ê° ì—°êµ¬ì‹¤ì—ì„œ ì‘ì„±í•œ win32ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ ì¸ìì „ë‹¬í•´ì„œ ë³µì¡° í•˜ë„ë¡ í•´ì£¼ì„¸ìš”
    srcs = askopenfilenames(initialdir="", filetypes=(("All", "*.*"), ("All Files", "*.*")), title="Choose a file.")
    if srcs == '':   # ì‚¬ìš©ìê°€ ask ì°½ì„ ìº”ìŠ¬ ëˆ„ë¥¸ ê²½ìš° ì•„ì›ƒ
        return

    for iii, seq1 in enumerate(srcs):
        src_plus_name = os.path.splitext(seq1)[0]   # íŒŒì¼ê²½ë¡œ+íŒŒì¼ì´ë¦„
        ext = os.path.splitext(seq1)[1]             # í™•ì¥ì
        name = os.path.basename(src_plus_name)      # íŒŒì¼ì´ë¦„

        print_dual(text_2_3, f'({iii + 1}/{len(srcs)}) {name}{ext}')
        vid3.changevideo(seq1)  # ì…ë ¥ì˜ìƒ ë„ìš°ê¸°

        print('(d) ë”ë¯¸íˆë“ ì—¬ë¶€í™•ì¸');  non_block_threding_popen(text_2_3, "python.exe dummy_hidden.py %s" % seq1)         # 1.1 ë”ë¯¸-íˆë“  íŒë³„ëª¨ë“œ ì‹¤í–‰ (ì„ì‹œ í•˜ë“œì½”ë”©)
        if 'hidden' in text_2_3.get('end-2lines', END):                                                                 # ì‹œë‚˜ë¦¬ì˜¤ 3       # ë”ë¯¸-íˆë“  ë³µì¡°
            print_dual(text_2_3, "dummy-hidden restore start")
            non_block_threding_popen(text_2_3, "python.exe dummy_hidden.py %s %s" % (seq1, '1'))                        # ë”ë¯¸-íˆë“  ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡°ëª¨ë“œ ì‹¤í–‰
            vid4.changevideo(src_plus_name + '_restored' + ext)                                                         # ë³µì¡°ëœ _restored íŒŒì¼ ë””ìŠ¤í”Œë ˆì´
            print_dual(text_2_3, "dummy-hidden restore complete") ; continue

        non_block_threding_popen(text_2_3, "python.exe codec_prediction.py %s" % seq1)           ## ë”¥ëŸ¬ë‹ìœ¼ë¡œ ì½”ë± ì‹ë³„          # 11ê°œ ì½”ë± í›„ë³´ì— ëŒ€í•œ í™•ë¥  ë°˜í™˜

        frequency =  text_2_3.get('end-2lines', END)[23:-3].split(',')                                # {MPEG2 H.263 H.264 H.265 IVC VP8 JPEG JPEG2000 BMP PNG TIFF} ìˆœì„œë¡œ catched_last1_line ë³€ìˆ˜ì— ì €ì¥,,, ê° ì‹œë‚˜ë¦¬ì˜¤ íŒë‹¨ê³¼ì •ì—ì„œ í™œìš©
        frq_dict = {c:int(frequency[i]) for i, c in enumerate(codec)}
        frq_dict = sorted(frq_dict.items(), key=operator.itemgetter(1), reverse=True)

        for c, v in frq_dict:                                                           # ë”¥ëŸ¬ë‹ì´ íŒë‹¨í•œ í™•ë¥  ìˆœì„œëŒ€ë¡œ ë³µì¡°ê³¼ì • ìˆ˜í–‰   ì½”ë±ë³„ë¡œ í™•ë¥ ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ë°˜ë³µ
            print_dual(text_2_3, '%s ì½”ë±ì˜ ë³€í˜• ì‹œë‚˜ë¦¬ì˜¤ ì˜ˆì¸¡ì¤‘..' % c)
            if c is 'MPEG-2':
                if subprocess.call("start_code_decryptor.exe %s" % seq1) == 0: ## ì‹œë‚˜ë¦¬ì˜¤4 header ë³€ì¡° check
                    print_dual(text_2_3, '2. ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.')
                    print_dual(text_2_3, 'header ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..')
                    vid4.changevideo(seq1 + '.restored')
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    time.sleep(0.2)
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # MPEG-2ì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'H.263':
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # H.263ì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'H.264':
                if subprocess.call("start_code_decryptor.exe %s" % seq1) == 0: ## ì‹œë‚˜ë¦¬ì˜¤4 header ë³€ì¡° check
                    print_dual(text_2_3, '2. ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.')
                    print_dual(text_2_3, 'header ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..')
                    vid4.changevideo(seq1 + '.restored')
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    time.sleep(0.2)
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # H.264ì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'H.265':
                if subprocess.call("start_code_decryptor.exe %s" % seq1) == 0: ## ì‹œë‚˜ë¦¬ì˜¤4 header ë³€ì¡° check
                    print_dual(text_2_3, '2. ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.')
                    print_dual(text_2_3, 'header ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..')
                    vid4.changevideo(seq1 + '.restored')
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    time.sleep(0.2)
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # hevcì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'IVC':
                if subprocess.call("start_code_decryptor.exe %s" % seq1) == 0: ## ì‹œë‚˜ë¦¬ì˜¤4 header ë³€ì¡° check
                    print_dual(text_2_3, '2. ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.')
                    print_dual(text_2_3, 'header ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..')
                    vid4.changevideo(seq1 + '.restored')
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    time.sleep(0.2)
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # IVCì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'VP8':
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # VP8ì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'JPEG':
                if subprocess.call(['python.exe', 'JPEG.py', seq1, '2']) == 0:  ## ì‹œë‚˜ë¦¬ì˜¤5 JPEG ì–‘ìí™” í…Œì´ë¸” ë³€ì¡° check
                    print_dual(text_2_3, "JPEG ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..")
                    non_block_threding_popen(text_2_3, "python.exe JPEG.py %s %d" % (seq1, 1))
                    vid4.changevideo(seq1.replace('Distorted', 'Restored'))
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # JPEGì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'JPEG2000':
                if subprocess.call(['python.exe', 'JPEG.py', seq1, '2']) == 0:  ## ì‹œë‚˜ë¦¬ì˜¤5 JPEG ì–‘ìí™” í…Œì´ë¸” ë³€ì¡° check
                    print_dual(text_2_3, "JPEG ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..")
                    non_block_threding_popen(text_2_3, "python.exe JPEG.py %s %d" % (seq1, 1))
                    vid4.changevideo(seq1.replace('Distorted', 'Restored'))
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # JPEG2000ì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°

            if c is 'BITMAP':
                if subprocess.call(['python.exe', 'bmp_scenario.py', seq1, '2']) == 0:  ## ì‹œë‚˜ë¦¬ì˜¤6 BMP ë³€ì¡° check
                    print_dual(text_2_3, "BMP ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..")
                    non_block_threding_popen(text_2_3, "python.exe bmp_scenario.py %s %d" % (seq1, 1))
                    vid4.changevideo(seq1.replace('Distorted.bmp', 'Restored.bmp'))
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # BITMAPì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END):
                    do_inv(text_2_3, seq1);
                    break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):
                    do_dxor(text_2_3, seq1); break  # xor ë³µì¡°
            if c is 'PNG':
                if subprocess.call(['python.exe', 'png_scenario.py', seq1, '2']) == 0:  ## ì‹œë‚˜ë¦¬ì˜¤7 PNG ë³€ì¡° check
                    print_dual(text_2_3, "PNG ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..")
                    non_block_threding_popen(text_2_3, "python.exe png_scenario.py %s %d" % (seq1, 1))
                    vid4.changevideo(seq1.replace('Distorted.png', 'Restored.png'))
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # PNGì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°
            if c is 'TIFF':
                if subprocess.call(['python.exe', 'tiff_scenario.py', seq1, '2']) == 0:  ## ì‹œë‚˜ë¦¬ì˜¤8 TIFF ë³€ì¡° check
                    print_dual(text_2_3, "TIFF ë³µì¡° ì¤‘ì…ë‹ˆë‹¤..")
                    non_block_threding_popen(text_2_3, "python.exe tiff_scenario.py %s %d" % (seq1, 1))
                    vid4.changevideo(seq1.replace('Distorted.tiff', 'Restored.tiff'))
                    print_dual(text_2_3, 'ë³µì¡°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.')
                    break
                non_block_threding_popen(text_2_3, "python.exe utils.py %s %s" % (seq1, c))     # TIFFì— ëŒ€í•œ inv xor íŒë‹¨
                if 'inverse' in text_2_3.get('end-2lines', END): do_inv(text_2_3, seq1); break  # inv ë³µì¡°
                elif 'xor' in text_2_3.get('end-2lines', END):  do_dxor(text_2_3, seq1); break  # xor ë³µì¡°







            #else:
            #    print_dual(text_2_3, '%s <- ì´ ë§ˆì§€ë§‰ ë©”ì„¸ì§€ë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆê¸°ì— ë³µì¡° ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë„˜ì–´ê°€ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í˜¹ì€ ë³µì¡° í”„ë¡œì„¸ìŠ¤ê°€ ì˜¤ë¥˜ì¢…ë£Œ í•˜ì˜€ìŒ' % catched_last1_line[:-2])

        print_dual(text_2_3, " ")           # íŒŒì¼ê°„ ì‚¬ì´ ê³µë°±
        window.focus_force()
        # winsound.PlaySound('SystemQuestion', winsound.SND_ALIAS)
        time.sleep(0.2)


# ì—¬ê¸°ê¹Œì§€ ë³µì¡°ê³¼ì •
#########################################################################################################
#########################################################################################################
# ì´í›„ UI ê´€ë ¨ ì½”ë“œ
def release(event):
    def ddd(vid, slider):
        current = int(vid.vid.get(1))
        goingto = int(vid.frame_count * slider.get() / 100) + 1

        if current < goingto:
            nn = goingto - current - 1
            for n in range(1, nn):
                vid.get_frame()
            tt, vid.frame = vid.get_frame()
            print(current, '    ', goingto)
        elif current > goingto:
            print(current, '    ', goingto)
            vid.vid.set(1, goingto)
            current = int(vid.vid.get(1))
            nn = goingto - current - 1
            for n in range(1, nn):
                vid.get_frame()
            tt, vid.frame = vid.get_frame()
            print('    ', current, '    ', goingto)
        time.sleep(0.81)

    if event.widget.master.winfo_name() == '!frame':
        ddd(vid1, sli1)
    elif event.widget.master.winfo_name() == '!frame2':
        ddd(vid3, sli2)


def sliderdrag(event):
    # time.sleep(0.02)
    # release(event)
    None


window = tkinter.Tk()
window.title('UI test')
window.iconbitmap('ho.ico')
window.geometry("845x705+900+160")

style = tkinter.ttk.Style()  # https://wiki.tcl-lang.org/page/List+of+ttk+Themes
style.theme_create("yummy", parent='winnative', settings={  # ì»¤ìŠ¤í…€ ìŠ¤íƒ€ì¼ì„ ë§Œë“¤ì–´ì•¼ë§Œ íƒ­ë°°ê²½ìƒ‰ì´ ë³€ê²½ê°€ëŠ¥í•˜ë°
    "TNotebook": {"configure": {"tabmargins": [7, 5, 0, 0]}},
    "TNotebook.Tab": {
        "configure": {"padding": [14, 5], "background": '#cfdfc5'},  # í°êµ­ë°©ìƒ‰
        "map": {"background": [("selected", '#FFFFFF')],  # í°ìƒ‰
                "expand": [("selected", [1, 1, 1, 1])]}}})
style.theme_use("yummy")
tkinter.ttk.Style().configure("TNotebook", background='#536349')  # êµ­ë°©ìƒ‰

# tkinter.ttk.Style().configure("TNotebook", background='#536349')        #êµ­ë°©ìƒ‰
# tkinter.ttk.Style().configure('TNotebook.Tab', padding=[11, 4], background='red',foreground='blue' )
# tkinter.ttk.Style().map('TNotebook.Tab', background=[('selected', 'yellow')])

notebook = tkinter.ttk.Notebook(window, width=845, height=670)
notebook.pack()

# Tap 1
frame1 = tkinter.Frame(window)
notebook.add(frame1, text="ë³€ì¡°")

Origin_labelframe_1 = tkinter.LabelFrame(frame1, text="Origin")
Modified_labelframe_1 = tkinter.LabelFrame(frame1, text="Modified")
States_labelframe_1 = tkinter.LabelFrame(frame1, text="States")

Origin_labelframe_1.pack()
Modified_labelframe_1.pack()
States_labelframe_1.pack()

# Vertical (y) Scroll Bar
yscrollbar = Scrollbar(States_labelframe_1)
yscrollbar.pack(side="right", fill="both")

# text_1_1 = Text(Origin_labelframe_1, width=50, height=20)
# text_1_2 = Text(Modified_labelframe_1, width=50, height=20)
text_1_3 = Text(States_labelframe_1, width=113, height=13, wrap=NONE, yscrollcommand=yscrollbar.set)

# text_1_1.insert(tkinter.INSERT, '''Origin''')
# text_1_2.insert(tkinter.INSERT, '''Modified''')
text_1_3.insert(tkinter.INSERT, '''''')

# text_1_1.pack()
# text_1_2.pack()
text_1_3.pack()

# Configure the scrollbars
yscrollbar.config(command=text_1_3.yview)

sli1 = DoubleVar();
slider_1 = Scale(frame1, from_=1, to=101, orient=HORIZONTAL, length=810, variable=sli1)
slider_1.bind("<B1-Motion>", sliderdrag)
slider_1.bind("<ButtonRelease-1>", release)
slider_1.pack()

# btn_1_2 = tkinter.Button(frame1, text="ã…")
# btn_1_3 = tkinter.Button(frame1, text=">>")

# Tap 2
frame2 = tkinter.Frame(window)
notebook.add(frame2, text="ë³µì¡°")

Origin_labelframe_2 = tkinter.LabelFrame(frame2, text="Modified")
Modified_labelframe_2 = tkinter.LabelFrame(frame2, text="Recovered")
States_labelframe_2 = tkinter.LabelFrame(frame2, text="States")

Origin_labelframe_2.pack()
Modified_labelframe_2.pack()
States_labelframe_2.pack()

# Vertical (y) Scroll Bar
yscrollbar = Scrollbar(States_labelframe_2)
yscrollbar.pack(side="right", fill="both")

# text_2_1 = Text(Origin_labelframe_2, width=50, height=20)
# text_2_2 = Text(Modified_labelframe_2, width=50, height=20)
text_2_3 = Text(States_labelframe_2, width=113, height=13, wrap=NONE, yscrollcommand=yscrollbar.set)

# text_2_1.insert(tkinter.INSERT, '''Modified''')
# text_2_2.insert(tkinter.INSERT, '''Recovered''')
text_2_3.insert(tkinter.INSERT, '''''')

# text_2_1.pack()
# text_2_2.pack()
text_2_3.pack()

# Configure the scrollbars
yscrollbar.config(command=text_2_3.yview)

# combobox
# combo_1_1 = Combobox(frame1)
# combo_1_1['values'] = ("MPEG-2", "H.263", "H.264", "HEVC", "IVC", "VP8", "JPEG", "JPEG2000", "BMP", "PNG", "TIFF")
# combo_1_1.current(0)  # set the selected item


combo_1_2 = Combobox(frame1)
combo_1_2['values'] = ("Scenario-1 inverse", "Scenario-2 xor", "Scenario-3 ë”ë¯¸-íˆë“ ", "Scenario-4 start code", "Scenario-5 jpg, j2k", "Scenario-6 bmp", "Scenario-7 png", "Scenario-8 tiff")
combo_1_2.bind("<<ComboboxSelected>>", lambda event: canvas_loading.show() or scenario_act(event) or window.focus_force() or canvas_loading.forget())  # í•¨ìˆ˜ ì£¼ì†Œ ì „ë‹¬ì¸ë° orì´ ë¨¹íˆë„¤...
combo_1_2.current(0)  # set the selected item

# combo_1_1.place(x=150, y=0)
combo_1_2.place(x=150, y=10)

sli2 = DoubleVar();
slider_2 = Scale(frame2, from_=1, to=101, orient=HORIZONTAL, length=810, variable=sli2)
slider_2.bind("<B1-Motion>", sliderdrag)
slider_2.bind("<ButtonRelease-1>", release)
slider_2.pack()

#


# button click event set
# btn_1 = tkinter.Button(window, text='input sequence & encode', command=lambda: vid1.changevideo(), compound=LEFT)
# btn_2 = tkinter.Button(window, text='distortion', command=lambda: vid2.changevideo(), compound=LEFT)
# btn_3 = tkinter.Button(window, text='load model & classify', command=lambda: vid3.changevideo(), compound=LEFT)
# btn_4 = tkinter.Button(window, text='recover', command=lambda: vid4.changevideo(), compound=LEFT)

# text_1_1 = Text(frame1,width = 10,height=1 )
btn_1_1 = tkinter.Button(frame1, text="input stream", command=lambda: scenario_act('askmode') or vid2.changevideo('close'))
# btn_1_2 = tkinter.Button(frame1, text="Encode", command=lambda: vid2.detect(text_1_3, combo_1_2.current()+1, codec_list.index(os.path.splitext(vid1.video_source)[1]), os.path.splitext(vid1.video_source)[0]))
# vid2.detect(text_1_3)
# vid2.detect(text_1_3, combo_1_2.current()+1, codec_list.index(os.path.splitext(vid1.video_source)[1]), os.path.splitext(vid1.video_source)[0])
# detect.main(combo_1_2.current(),3,vid1.video_source)
# text_2_1 = Text(frame2,width = 10,height=1 )
btn_2_1 = tkinter.Button(frame2, text="restore stream", command=lambda: scenario_inv_act() or window.focus_force())  # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œë˜ë©´ ìœˆë„ìš°ê°€ ê¹œë¹¡ì´ë„ë¡ ì•ŒëŒ
# btn_2_2 = tkinter.Button(frame2, text="Decode", command=lambda: vid4.detect_inv(text_2_3, os.path.splitext(vid3.video_source)))


# button position
# text_1_1.place(x = 110, y = 5)
btn_1_1.place(x=10, y=10)
# btn_1_2.place(x=53, y=0)
# text_2_1.place(x = 110, y = 5)
btn_2_1.place(x=10, y=10)
# btn_2_2.place(x=53, y=0)
# btn_1_2.place(x=0, y=350)
# btn_2_2.place(x=0, y=350)
# btn_1_3.place(x=30, y=350)
# btn_2_3.place(x=30, y=350)

# windows positions
Origin_labelframe_1.place(x=10, y=50)
Origin_labelframe_2.place(x=10, y=50)
Modified_labelframe_1.place(x=460, y=50)
Modified_labelframe_2.place(x=460, y=50)
States_labelframe_1.place(x=10, y=450)
States_labelframe_2.place(x=10, y=450)

slider_1.place(x=10, y=400)
slider_2.place(x=10, y=400)

vid1 = LoadDisplay(Origin_labelframe_1, 0, 0)
vid2 = LoadDisplay(Modified_labelframe_1, 0, 0)
vid3 = LoadDisplay(Origin_labelframe_2, 0, 0)
vid4 = LoadDisplay(Modified_labelframe_2, 0, 0)

text_1_a = Text(Origin_labelframe_1, width=40, height=1)
text_1_a.configure(background=window["bg"], border=0);
text_1_a.pack()
text_1_b = Text(Origin_labelframe_2, width=40, height=1);
text_1_b.configure(background=window["bg"], border=0);
text_1_b.pack()
text_2_a = Text(Modified_labelframe_1, width=40, height=1);
text_2_a.configure(background=window["bg"], border=0);
text_2_a.pack()
text_2_b = Text(Modified_labelframe_2, width=40, height=1);
text_2_b.configure(background=window["bg"], border=0);
text_2_b.pack()


class canvas_loding_class:
    def __init__(self, width, height, x, y, hide=1):
        self.hide = hide
        self.x = x
        self.y = y
        self.canvas_loadingimage = tkinter.Canvas(window, width=width, height=height, bg="yellow", bd=0,
                                                  highlightthickness=0, relief='ridge')
        self.canvas_loadingimage.place(x=x, y=y)
        self.vid = cv2.VideoCapture('load_lgreen.gif')
        ret, self.temframe = self.vid.read()
        cv2.cvtColor(self.temframe, cv2.COLOR_BGR2RGB)
        self.photo = PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(self.temframe))
        self.canvas_loadingimage.create_image(0, 0, image=self.photo, anchor=tkinter.NW)
        self.forget()
        self.update()

    def update(self):
        if self.hide == 1:
            None
        else:
            try:
                ret, self.temframe = self.vid.read()  # cvê°€ ì½”ë±ëª¨ë¥¼ê²½ìš° ì—ëŸ¬ë¿œìŒ
                cv2.cvtColor(self.temframe, cv2.COLOR_BGR2RGB)
            except:
                self.vid = cv2.VideoCapture('load_lgreen.gif')  # opencv ì´ìƒí•œê²Œ í”„ë ˆì„ ì¬ìƒ í• ë‹¹ëŸ‰ë§Œ ì±„ìš°ë©´ ì¢…ë£Œë˜ë²„ë¦¬ë„¤ ã„·  bitì€ ì˜¤ë¥˜ë‚ ë“¯
                ret, self.temframe = self.vid.read()
            self.photo = PIL.ImageTk.PhotoImage(image=PIL.Image.fromarray(self.temframe))
            self.canvas_loadingimage.create_image(0, 0, image=self.photo, anchor=tkinter.NW)
        window.after(27, self.update)
        # window.update()

    def forget(self):
        self.hide = 1
        self.canvas_loadingimage.place_forget()
        window.update()

    def show(self):
        self.hide = 0
        self.canvas_loadingimage.place(x=self.x, y=self.y)
        window.update()


canvas_loading = canvas_loding_class(290, 290, 250, 200)

for filename in glob("1t_youcandelete*"): os.remove(filename)
srcs_g('')  # ì „ì—­ë³€ìˆ˜ ì´ˆê¸°í™”

window.mainloop()
for filename in glob("1t_youcandelete*"): os.remove(filename)